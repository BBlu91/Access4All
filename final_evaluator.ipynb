{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0ff3586-d2c6-4ab2-861e-56a358dde412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluation Framework (No Ground-Truth Setting)\n",
    "\n",
    "This notebook evaluates the **correctness, robustness, and internal consistency** of the Access4All accessibility scores stored in `default.access4all_final_scores`.\n",
    "\n",
    "Because no reliable ground-truth labels exist for large-scale accessibility quality across cities, standard supervised metrics (e.g., accuracy, RMSE) are not applicable. Instead, we validate the scoring logic using **axiom-based and property-driven evaluation**, ensuring that the results obey mandatory domain constraints (hard blocks), exhibit correct directional behavior (monotonicity), remain stable under small parameter changes (rank stability), respect non-compensatory veto logic, and avoid redundancy between scoring components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "419ba840-4120-462a-b6ec-b57d5f9648b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### This cell runs the evaluation suite on `default.access4all_final_scores`, checking hard invariants, slope-based monotonicity, rank stability under small weight perturbations, conflict/veto behavior, and component correlations.###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa31c285-59f0-4d75-8427-834a262f1d52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import numpy as np\n",
    "\n",
    "# --- Base configuration ---\n",
    "# Update table name if needed\n",
    "TABLE_NAME = \"default.access4all_final_scores\"\n",
    "W1, W2, W3 = 0.20, 0.35, 0.45\n",
    "\n",
    "# Cache for performance during iterative evaluation checks\n",
    "df = spark.table(TABLE_NAME).cache()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PILLAR 1 & 2: Logical validity and monotonicity checks\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def run_logical_checks(df):\n",
    "    print(\"--- Pillar 1: Hard Invariants & Correctness ---\")\n",
    "    \n",
    "    # Hard block invariant: if any hard block exists, final score must be 0\n",
    "    hard_block_fail = df.filter(\n",
    "        (F.col(\"any_hard_block\") == True) & (F.col(\"final_score\") > 0)\n",
    "    ).count()\n",
    "    \n",
    "    # Final score must be within [0,1]\n",
    "    range_fail = df.filter(\n",
    "        (F.col(\"final_score\") < 0) | (F.col(\"final_score\") > 1)\n",
    "    ).count()\n",
    "    \n",
    "    print(f\"✅ Hard Block Violations: {hard_block_fail}\")\n",
    "    print(f\"✅ Score Range Violations [0,1]: {range_fail}\")\n",
    "\n",
    "def run_monotonicity_tests(df):\n",
    "    print(\"\\n--- Pillar 2: Monotonicity (Directional Sanity) ---\")\n",
    "    \n",
    "    # Terrain slope (v3): score should decrease as slope increases\n",
    "    print(\"V3 Score by Slope Bucket:\")\n",
    "    df.withColumn(\n",
    "        \"slope_bucket\",\n",
    "        F.when(F.col(\"slope_p50_pct_200m\") < 3, \"1. Flat (<3%)\")\n",
    "         .when(F.col(\"slope_p50_pct_200m\") < 6, \"2. Mild (3–6%)\")\n",
    "         .when(F.col(\"slope_p50_pct_200m\") < 10, \"3. Steep (6–10%)\")\n",
    "         .otherwise(\"4. Extreme (>10%)\")\n",
    "    ) \\\n",
    "    .groupBy(\"slope_bucket\") \\\n",
    "    .agg(\n",
    "        F.avg(\"v3_score\").alias(\"avg_v3\"),\n",
    "        F.count(\"*\").alias(\"count\")\n",
    "    ) \\\n",
    "    .orderBy(\"slope_bucket\") \\\n",
    "    .show()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PILLAR 5: Rank stability (sensitivity analysis)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def test_rank_stability(df, perturbation=0.05, top_k=1000):\n",
    "    \"\"\"\n",
    "    Tests whether a small change in weights (e.g. +5% to terrain weight)\n",
    "    drastically changes the ranking.\n",
    "    High stability (>90%) indicates a robust scoring model.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Pillar 5: Rank Stability (Top {top_k}) ---\")\n",
    "    \n",
    "    window_spec = Window.orderBy(F.desc(\"final_score\"))\n",
    "    \n",
    "    # Original top-K based on final score\n",
    "    original_top = (\n",
    "        df.withColumn(\"rank\", F.row_number().over(window_spec))\n",
    "          .filter(F.col(\"rank\") <= top_k)\n",
    "          .select(\"property_id\")\n",
    "          .collect()\n",
    "    )\n",
    "    \n",
    "    orig_set = set(row[\"property_id\"] for row in original_top)\n",
    "    \n",
    "    # Recompute score with a small perturbation in v3 weight\n",
    "    perturbed_w3 = W3 + perturbation\n",
    "    perturbed_df = df.withColumn(\n",
    "        \"p_score\",\n",
    "        (F.lit(W1 + W2 + perturbed_w3) /\n",
    "         ((F.lit(W1) / (F.col(\"v1_score\") + 1e-6)) +\n",
    "          (F.lit(W2) / (F.col(\"v2_score\") + 1e-6)) +\n",
    "          (F.lit(perturbed_w3) / (F.col(\"v3_score\") + 1e-6))))\n",
    "    )\n",
    "    \n",
    "    new_window = Window.orderBy(F.desc(\"p_score\"))\n",
    "    new_top = (\n",
    "        perturbed_df.withColumn(\"rank\", F.row_number().over(new_window))\n",
    "                    .filter(F.col(\"rank\") <= top_k)\n",
    "                    .select(\"property_id\")\n",
    "                    .collect()\n",
    "    )\n",
    "    \n",
    "    new_set = set(row[\"property_id\"] for row in new_top)\n",
    "    \n",
    "    overlap = len(orig_set.intersection(new_set)) / top_k\n",
    "    print(f\"Rank Stability Score (Jaccard Overlap): {overlap:.2%}\")\n",
    "    \n",
    "    if overlap < 0.80:\n",
    "        print(\"⚠️ Warning: Ranking is overly sensitive to small weight changes.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PILLAR 6: Conflict auditing (veto behavior)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def audit_conflicts(df):\n",
    "    \"\"\"\n",
    "    Identifies listings with conflicting signals:\n",
    "    e.g., highly accessible property (v1) but very poor surrounding terrain (v3).\n",
    "    Used to verify veto / non-compensatory behavior.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Pillar 6: Conflict Auditing (Veto Check) ---\")\n",
    "    \n",
    "    conflicts = df.filter(\n",
    "        (F.col(\"v1_score\") > 0.8) & (F.col(\"v3_score\") < 0.2)\n",
    "    )\n",
    "    \n",
    "    count = conflicts.count()\n",
    "    print(f\"Found {count} listings with good property but bad terrain.\")\n",
    "    \n",
    "    # Final score should remain low in such cases\n",
    "    failures = conflicts.filter(F.col(\"final_score\") > 0.4).count()\n",
    "    print(f\"Veto Failures (final score stayed too high): {failures}\")\n",
    "    \n",
    "    if count > 0:\n",
    "        conflicts.select(\n",
    "            \"property_id\",\n",
    "            \"city\",\n",
    "            \"v1_score\",\n",
    "            \"v3_score\",\n",
    "            \"final_score\"\n",
    "        ).show(5)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PILLAR 8: Component independence\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def check_correlations(df):\n",
    "    \"\"\"\n",
    "    Ensures that v1, v2, and v3 capture different information.\n",
    "    High correlation (>0.7) may indicate redundancy.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Pillar 8: Component Independence (Pearson Correlation) ---\")\n",
    "    cols = [\"v1_score\", \"v2_score\", \"v3_score\"]\n",
    "    \n",
    "    for i in range(len(cols)):\n",
    "        for j in range(i + 1, len(cols)):\n",
    "            corr = df.stat.corr(cols[i], cols[j])\n",
    "            print(f\"Correlation {cols[i]} vs {cols[j]}: {corr:.4f}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Execution\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "run_logical_checks(df)\n",
    "run_monotonicity_tests(df)\n",
    "test_rank_stability(df)\n",
    "audit_conflicts(df)\n",
    "check_correlations(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61396c33-730a-432d-959d-6eba1667e1c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###This cell evaluates `default.access4all_final_scores` via hard invariants, slope-bucket monotonicity (median/p90), Top-K rank stability under a small renormalized weight perturbation, conflict/veto auditing, and component Pearson correlations.\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f511737-67b4-47f4-9a7a-269a6be791dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "TABLE_NAME = \"default.access4all_final_scores\"\n",
    "df = spark.table(TABLE_NAME).cache()\n",
    "\n",
    "W1, W2, W3 = 0.20, 0.35, 0.45\n",
    "BONUS_MAX = 0.075  # 0.15*(1-0.5)\n",
    "K = 1000\n",
    "\n",
    "# -------------------------\n",
    "# Pillar 1: Core invariants (minimal but correct)\n",
    "# -------------------------\n",
    "print(\"--- Pillar 1: Hard Invariants ---\")\n",
    "\n",
    "viol_hard_block = df.filter((F.col(\"any_hard_block\") == True) & (F.col(\"final_score\") > 0)).count()\n",
    "viol_range = df.filter((F.col(\"final_score\") < 0) | (F.col(\"final_score\") > 1)).count()\n",
    "\n",
    "# if any component is 0 -> harmonic should be 0 -> final should be 0 (bonus only applies when v3>=0.5, so if v3=0 it's irrelevant)\n",
    "viol_any_zero = df.filter(\n",
    "    ((F.col(\"v1_score\") == 0) | (F.col(\"v2_score\") == 0) | (F.col(\"v3_score\") == 0)) &\n",
    "    (F.col(\"final_score\") > 0) &\n",
    "    (F.col(\"any_hard_block\") == False)\n",
    ").count()\n",
    "\n",
    "print(\"Hard block => final_score=0 violations:\", viol_hard_block)\n",
    "print(\"final_score in [0,1] violations:\", viol_range)\n",
    "print(\"Any(v1,v2,v3)=0 => final_score=0 violations:\", viol_any_zero)\n",
    "\n",
    "# -------------------------\n",
    "# Pillar 2: Monotonicity sanity (use median)\n",
    "# -------------------------\n",
    "print(\"\\n--- Pillar 2: Monotonicity (median by bucket) ---\")\n",
    "\n",
    "slope_bucketed = (\n",
    "    df.withColumn(\n",
    "        \"slope_bucket\",\n",
    "        F.when(F.col(\"slope_p50_pct_200m\").isNull(), F.lit(\"NULL\"))\n",
    "         .when(F.col(\"slope_p50_pct_200m\") < 3, F.lit(\"<3%\"))\n",
    "         .when(F.col(\"slope_p50_pct_200m\") < 6, F.lit(\"3-6%\"))\n",
    "         .when(F.col(\"slope_p50_pct_200m\") < 10, F.lit(\"6-10%\"))\n",
    "         .when(F.col(\"slope_p50_pct_200m\") < 15, F.lit(\"10-15%\"))\n",
    "         .otherwise(F.lit(\">=15%\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "(slope_bucketed.groupBy(\"slope_bucket\")\n",
    " .agg(\n",
    "     F.count(\"*\").alias(\"n\"),\n",
    "     F.expr(\"percentile_approx(v3_score, 0.5)\").alias(\"median_v3\"),\n",
    "     F.expr(\"percentile_approx(v3_score, 0.9)\").alias(\"p90_v3\"),\n",
    " )\n",
    " .orderBy(\"slope_bucket\")\n",
    " .show(200, truncate=False)\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Helper: recompute final_score under perturbed weights (aligned to YOUR spec)\n",
    "# -------------------------\n",
    "def compute_final_expr(v1, v2, v3, v2_hb, v3_hb, w1, w2, w3):\n",
    "    any_zero = (v1 == 0) | (v2 == 0) | (v3 == 0)\n",
    "    any_hb = v2_hb | v3_hb\n",
    "\n",
    "    harmonic = F.when(\n",
    "        any_zero, F.lit(0.0)\n",
    "    ).otherwise(\n",
    "        (F.lit(w1 + w2 + w3)) / (F.lit(w1)/v1 + F.lit(w2)/v2 + F.lit(w3)/v3)\n",
    "    )\n",
    "\n",
    "    bonus = F.when(v3 >= 0.5, (v3 - 0.5) * 0.15).otherwise(F.lit(0.0))\n",
    "    raw = harmonic + bonus\n",
    "    clamped = F.greatest(F.lit(0.0), F.least(F.lit(1.0), raw))\n",
    "\n",
    "    return F.when(any_hb, F.lit(0.0)).otherwise(clamped)\n",
    "\n",
    "# -------------------------\n",
    "# Extra Pillar: Rank Stability (Top-K overlap) — Correct + deterministic\n",
    "# -------------------------\n",
    "print(f\"\\n--- Rank Stability (Top {K} overlap) ---\")\n",
    "\n",
    "orig_top_ids = set(\n",
    "    r[\"property_id\"]\n",
    "    for r in df.orderBy(F.desc(\"final_score\")).select(\"property_id\").limit(K).collect()\n",
    ")\n",
    "\n",
    "# Perturb weights (example: +5% to w3, then renormalize so weights sum to 1)\n",
    "perturb = 0.05\n",
    "w1p, w2p, w3p = W1, W2, W3 * (1 + perturb)\n",
    "s = w1p + w2p + w3p\n",
    "w1p, w2p, w3p = w1p/s, w2p/s, w3p/s\n",
    "\n",
    "df_p = df.withColumn(\n",
    "    \"final_score_perturbed\",\n",
    "    compute_final_expr(\n",
    "        F.col(\"v1_score\"), F.col(\"v2_score\"), F.col(\"v3_score\"),\n",
    "        F.col(\"v2_hard_block\"), F.col(\"v3_hard_block\"),\n",
    "        w1p, w2p, w3p\n",
    "    )\n",
    ")\n",
    "\n",
    "new_top_ids = set(\n",
    "    r[\"property_id\"]\n",
    "    for r in df_p.orderBy(F.desc(\"final_score_perturbed\")).select(\"property_id\").limit(K).collect()\n",
    ")\n",
    "\n",
    "overlap = len(orig_top_ids.intersection(new_top_ids)) / K\n",
    "print(f\"Top-{K} overlap after +{int(perturb*100)}% w3 (renormalized): {overlap:.2%}\")\n",
    "\n",
    "# -------------------------\n",
    "# Conflict Auditing: good v1 but bad v3 should veto final score\n",
    "# -------------------------\n",
    "print(\"\\n--- Conflict Auditing (Veto check) ---\")\n",
    "conflicts = df.filter((F.col(\"v1_score\") >= 0.8) & (F.col(\"v3_score\") <= 0.2))\n",
    "n_conf = conflicts.count()\n",
    "n_bad = conflicts.filter(F.col(\"final_score\") > 0.4).count()\n",
    "print(\"Conflicts (v1>=0.8 & v3<=0.2):\", n_conf)\n",
    "print(\"Veto failures (final_score>0.4 among conflicts):\", n_bad)\n",
    "conflicts.select(\"property_id\",\"city\",\"v1_score\",\"v2_score\",\"v3_score\",\"final_score\",\"limiting_layer\",\"reasons\").show(20, truncate=False)\n",
    "\n",
    "# -------------------------\n",
    "# Independence: correlations (fix the loop)\n",
    "# -------------------------\n",
    "print(\"\\n--- Component Independence (Pearson corr) ---\")\n",
    "cols = [\"v1_score\",\"v2_score\",\"v3_score\"]\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        c = df.stat.corr(cols[i], cols[j])\n",
    "        print(f\"corr({cols[i]}, {cols[j]}) = {c:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "final_evaluator",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}