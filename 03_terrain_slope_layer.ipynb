{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "613ab630-c4ed-41b8-85c3-9d6635b2994f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Deep Data Layer â€” Copernicus Terrain Enrichment (v3)\n",
    "\n",
    "This notebook adds **terrain information** to Airbnb listings using the **Copernicus 30 m DEM** dataset.\n",
    "\n",
    "For each listing, it:\n",
    "- Finds the matching Copernicus terrain tile  \n",
    "- Analyzes elevation within a **200 m radius**  \n",
    "- Computes basic elevation and slope statistics  \n",
    "- Classifies the surrounding terrain into clear, rule-based categories  \n",
    "\n",
    "The output is a **deterministic v3 terrain table** that is used later in the final accessibility scoring.  \n",
    "This notebook contains **no exploration or analysis** and exists only to build the terrain data layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cd8bb11-55a7-4c3d-96c1-64907d2ff26b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Environment setup: install pinned geospatial dependencies for Copernicus DEM processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e830b66c-d182-418e-b1d3-2c93d42fec32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --force-reinstall \"numpy<2\" \"rasterio==1.4.4\" \"shapely<2.1\" \"pyproj<3.8\" requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3004be1-e152-4472-9fbf-19a58c8895f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Restart Python to activate newly installed geospatial dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "592ccb2a-8cfc-493b-9e2b-921e3314448b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbd082ae-eeb4-46c1-bb47-b42323be023d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Prepare listing point geometry (property_id, latitude, longitude) for terrain enrichment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfbd2fe0-ba95-42c4-8512-1fcd1c33027f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pts = (\n",
    "  spark.table(\"default.access4all_airbnb_v1_9cities\")\n",
    "  .selectExpr(\n",
    "      \"property_id\",\n",
    "      \"CAST(lat AS DOUBLE)  AS lat\",\n",
    "      \"CAST(`long` AS DOUBLE) AS lon\"\n",
    "  )\n",
    "  .dropna(subset=[\"lat\",\"lon\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25cc1206-75af-439f-baa9-052bb50d2cb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Fetch and cache the official Copernicus DEM tile index used to resolve required terrain tiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e121d25-3a2c-4304-a549-f23b4aebe057",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "tilelist_url = \"https://copernicus-dem-30m.s3.amazonaws.com/tileList.txt\"\n",
    "\n",
    "r = requests.get(tilelist_url, timeout=60)\n",
    "r.raise_for_status()\n",
    "\n",
    "tile_list = set(line.strip() for line in r.text.splitlines() if line.strip())\n",
    "\n",
    "print(\"tile list size:\", len(tile_list))\n",
    "print(\"sample:\", list(sorted(tile_list))[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "215d3b42-38e7-414d-8aa3-42db2317e631",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Copernicus DEM terrain enrichment: fetch tiles, extract 200m-buffer elevation stats, and derive slope-based context labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12acc47d-90f9-4b94-befa-ee1924b70c40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import Point, mapping\n",
    "from shapely.ops import transform as shp_transform\n",
    "from pyproj import Transformer\n",
    "from datetime import datetime\n",
    "\n",
    "# ------------------------\n",
    "# Config\n",
    "# ------------------------\n",
    "RADIUS_M = 200\n",
    "PIPELINE_VERSION = \"v3.3-final-pilot\"\n",
    "DEM_SOURCE = \"copernicus_dem_glo30_public\"\n",
    "DEM_RESOLUTION_M = 30.0\n",
    "\n",
    "# WGS84 -> WebMercator (meters)\n",
    "to3857 = Transformer.from_crs(\"EPSG:4326\", \"EPSG:3857\", always_xy=True)\n",
    "\n",
    "# ------------------------\n",
    "# Tile naming\n",
    "# ------------------------\n",
    "def fmt_ns(lat_deg: int) -> str:\n",
    "    return f\"N{lat_deg:02d}_00\" if lat_deg >= 0 else f\"S{abs(lat_deg):02d}_00\"\n",
    "\n",
    "def fmt_ew(lon_deg: int) -> str:\n",
    "    return f\"E{lon_deg:03d}_00\" if lon_deg >= 0 else f\"W{abs(lon_deg):03d}_00\"\n",
    "\n",
    "def tile_folder(lat: float, lon: float) -> str:\n",
    "    return f\"Copernicus_DSM_COG_10_{fmt_ns(math.floor(lat))}_{fmt_ew(math.floor(lon))}_DEM\"\n",
    "\n",
    "# ------------------------\n",
    "# Open DEM (tries common key patterns)\n",
    "# ------------------------\n",
    "def open_dem(folder: str):\n",
    "    base = \"https://copernicus-dem-30m.s3.amazonaws.com\"\n",
    "    candidates = [\n",
    "        f\"/vsicurl/{base}/{folder}/{folder}.tif\",\n",
    "        f\"/vsicurl/{base}/{folder}/{folder}.tiff\",\n",
    "        f\"/vsicurl/{base}/{folder}/DEM.tif\",\n",
    "        f\"/vsicurl/{base}/{folder}/dem.tif\",\n",
    "    ]\n",
    "    last_err = None\n",
    "    for url in candidates:\n",
    "        try:\n",
    "            return rasterio.open(url), url\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise last_err\n",
    "\n",
    "# ------------------------\n",
    "# Build 200m buffer in meters (3857), then reproject to src.crs for raster mask\n",
    "# ------------------------\n",
    "def buffer_geom_in_src_crs(lon, lat, src_crs, radius_m=200):\n",
    "    x, y = to3857.transform(lon, lat)\n",
    "    poly_3857 = Point(x, y).buffer(radius_m)\n",
    "\n",
    "    tf = Transformer.from_crs(\"EPSG:3857\", src_crs, always_xy=True)\n",
    "    poly_src = shp_transform(lambda xx, yy, zz=None: tf.transform(xx, yy), poly_3857)\n",
    "    return mapping(poly_src)\n",
    "\n",
    "# ------------------------\n",
    "# Validity mask: finite, plausible, not nodata\n",
    "# (0/neg treated as invalid to avoid void/ocean encodings causing spikes)\n",
    "# ------------------------\n",
    "def valid_mask(elev: np.ndarray, nodata):\n",
    "    finite = np.isfinite(elev)\n",
    "    plausible = (elev > 0) & (elev < 9000)  # wide bound\n",
    "    if nodata is None:\n",
    "        return finite & plausible\n",
    "    return finite & plausible & (elev != nodata)\n",
    "\n",
    "# ------------------------\n",
    "# Slope (% grade), CRS-aware pixel spacing\n",
    "# IMPORTANT: expects elev_nan has NaNs where invalid so gradients near void become NaN\n",
    "# ------------------------\n",
    "def slope_pct(elev_nan: np.ndarray, transform, src_crs, lat_center: float):\n",
    "    if src_crs is not None and getattr(src_crs, \"is_projected\", False):\n",
    "        dx = transform.a\n",
    "        dy = -transform.e\n",
    "    else:\n",
    "        dx_deg = transform.a\n",
    "        dy_deg = -transform.e\n",
    "        m_per_deg_lat = 111320.0\n",
    "        m_per_deg_lon = 111320.0 * np.cos(np.deg2rad(lat_center))\n",
    "        dx = dx_deg * m_per_deg_lon\n",
    "        dy = dy_deg * m_per_deg_lat\n",
    "\n",
    "    gy, gx = np.gradient(elev_nan.astype(\"float64\"), dy, dx)\n",
    "    return np.sqrt(gx*gx + gy*gy) * 100.0\n",
    "\n",
    "# ------------------------\n",
    "# Coverage + label rules (stable for 200m + 30m DEM)\n",
    "# ------------------------\n",
    "def coverage_label(r):\n",
    "    if r >= 0.90: return \"good\"\n",
    "    if r >= 0.70: return \"partial\"\n",
    "    return \"poor\"\n",
    "\n",
    "def terrain_label(cov, slope_p50, share_gt8):\n",
    "    if cov == \"poor\" or slope_p50 is None or share_gt8 is None:\n",
    "        return \"unknown_coverage\"\n",
    "    if slope_p50 <= 5.0 and share_gt8 <= 0.20:\n",
    "        return \"flat_supportive\"\n",
    "    if slope_p50 <= 8.0 and share_gt8 <= 0.35:\n",
    "        return \"moderate\"\n",
    "    return \"steep_challenging\"\n",
    "\n",
    "# ------------------------\n",
    "# Compute one listing\n",
    "# ------------------------\n",
    "def compute_one(pid, lat, lon):\n",
    "    base_out = {\n",
    "        \"property_id\": pid,\n",
    "        \"lat\": float(lat),\n",
    "        \"lon\": float(lon),\n",
    "        \"radius_m\": RADIUS_M,\n",
    "        \"dem_source\": DEM_SOURCE,\n",
    "        \"dem_resolution_m\": float(DEM_RESOLUTION_M),\n",
    "        \"pipeline_version\": PIPELINE_VERSION,\n",
    "        \"computed_at_utc\": datetime.utcnow().isoformat(),\n",
    "    }\n",
    "\n",
    "    folder = tile_folder(lat, lon)\n",
    "\n",
    "    # deterministic unknown if tile missing\n",
    "    if folder not in tile_list:\n",
    "        return {**base_out,\n",
    "            \"dem_valid_cell_ratio_200m\": 0.0,\n",
    "            \"dem_void_ratio_200m\": 1.0,\n",
    "            \"dem_coverage_label_200m\": \"poor\",\n",
    "            \"elev_min_200m\": None, \"elev_max_200m\": None, \"elev_range_200m\": None,\n",
    "            \"slope_p50_pct_200m\": None, \"slope_p90_pct_200m\": None, \"slope_max_pct_200m\": None,\n",
    "            \"share_area_slope_gt_8pct_200m\": None,\n",
    "            \"terrain_context_label_200m\": \"unknown_coverage\",\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        src, _ = open_dem(folder)\n",
    "        with src:\n",
    "            geom = buffer_geom_in_src_crs(lon, lat, src.crs, RADIUS_M)\n",
    "            out, out_transform = mask(src, [geom], crop=True, all_touched=True)\n",
    "            elev = out[0].astype(\"float64\")\n",
    "            nodata = src.nodata\n",
    "            src_crs = src.crs\n",
    "    except Exception:\n",
    "        return {**base_out,\n",
    "            \"dem_valid_cell_ratio_200m\": 0.0,\n",
    "            \"dem_void_ratio_200m\": 1.0,\n",
    "            \"dem_coverage_label_200m\": \"poor\",\n",
    "            \"elev_min_200m\": None, \"elev_max_200m\": None, \"elev_range_200m\": None,\n",
    "            \"slope_p50_pct_200m\": None, \"slope_p90_pct_200m\": None, \"slope_max_pct_200m\": None,\n",
    "            \"share_area_slope_gt_8pct_200m\": None,\n",
    "            \"terrain_context_label_200m\": \"unknown_coverage\",\n",
    "        }\n",
    "\n",
    "    valid = valid_mask(elev, nodata)\n",
    "    total = elev.size\n",
    "    valid_count = int(valid.sum())\n",
    "    ratio = float(valid_count / total) if total > 0 else 0.0\n",
    "    cov = coverage_label(ratio)\n",
    "\n",
    "    if cov == \"poor\":\n",
    "        return {**base_out,\n",
    "            \"dem_valid_cell_ratio_200m\": ratio,\n",
    "            \"dem_void_ratio_200m\": 1.0 - ratio,\n",
    "            \"dem_coverage_label_200m\": cov,\n",
    "            \"elev_min_200m\": None, \"elev_max_200m\": None, \"elev_range_200m\": None,\n",
    "            \"slope_p50_pct_200m\": None, \"slope_p90_pct_200m\": None, \"slope_max_pct_200m\": None,\n",
    "            \"share_area_slope_gt_8pct_200m\": None,\n",
    "            \"terrain_context_label_200m\": \"unknown_coverage\",\n",
    "        }\n",
    "\n",
    "    elev_v = elev[valid]\n",
    "    elev_min = float(elev_v.min())\n",
    "    elev_max = float(elev_v.max())\n",
    "    elev_range = float(elev_max - elev_min)\n",
    "\n",
    "    # void-safe slope: invalid -> NaN\n",
    "    elev_nan = elev.copy()\n",
    "    elev_nan[~valid] = np.nan\n",
    "\n",
    "    s = slope_pct(elev_nan, out_transform, src_crs, lat)\n",
    "\n",
    "    # only slopes that are finite and from valid elev\n",
    "    slope_ok = valid & np.isfinite(s)\n",
    "    if slope_ok.sum() == 0:\n",
    "        return {**base_out,\n",
    "            \"dem_valid_cell_ratio_200m\": ratio,\n",
    "            \"dem_void_ratio_200m\": 1.0 - ratio,\n",
    "            \"dem_coverage_label_200m\": cov,\n",
    "            \"elev_min_200m\": elev_min, \"elev_max_200m\": elev_max, \"elev_range_200m\": elev_range,\n",
    "            \"slope_p50_pct_200m\": None, \"slope_p90_pct_200m\": None, \"slope_max_pct_200m\": None,\n",
    "            \"share_area_slope_gt_8pct_200m\": None,\n",
    "            \"terrain_context_label_200m\": \"unknown_coverage\",\n",
    "        }\n",
    "\n",
    "    s_v = s[slope_ok]\n",
    "    slope_p50 = float(np.percentile(s_v, 50))\n",
    "    slope_p90 = float(np.percentile(s_v, 90))\n",
    "    slope_max = float(s_v.max())\n",
    "    share_gt8 = float(np.mean(s_v > 8.0))\n",
    "\n",
    "    label = terrain_label(cov, slope_p50, share_gt8)\n",
    "\n",
    "    return {**base_out,\n",
    "        \"dem_valid_cell_ratio_200m\": ratio,\n",
    "        \"dem_void_ratio_200m\": 1.0 - ratio,\n",
    "        \"dem_coverage_label_200m\": cov,\n",
    "        \"elev_min_200m\": elev_min, \"elev_max_200m\": elev_max, \"elev_range_200m\": elev_range,\n",
    "        \"slope_p50_pct_200m\": slope_p50,\n",
    "        \"slope_p90_pct_200m\": slope_p90,\n",
    "        \"slope_max_pct_200m\": slope_max,\n",
    "        \"share_area_slope_gt_8pct_200m\": share_gt8,\n",
    "        \"terrain_context_label_200m\": label,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb5e938b-84a9-4edb-9e85-ab4fdbbaa7c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Resolve each listing to its Copernicus DEM tile and flag whether the tile exists in the published index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d642de16-98c1-4f2c-83ce-d7dda6462d28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, types as T\n",
    "\n",
    "# anchor points from v1\n",
    "df_pts = (\n",
    "  spark.table(\"default.access4all_airbnb_v1_9cities\")\n",
    "  .selectExpr(\n",
    "      \"CAST(property_id AS STRING) AS property_id\",\n",
    "      \"CAST(lat AS DOUBLE) AS lat\",\n",
    "      \"CAST(`long` AS DOUBLE) AS lon\"\n",
    "  )\n",
    "  .dropna(subset=[\"lat\",\"lon\"])\n",
    ")\n",
    "\n",
    "# broadcast tile_list (Python set)\n",
    "tile_list_b = spark.sparkContext.broadcast(tile_list)\n",
    "\n",
    "@F.udf(\"string\")\n",
    "def tile_folder_udf(lat, lon):\n",
    "    import math\n",
    "    def fmt_ns(lat_deg: int) -> str:\n",
    "        return f\"N{lat_deg:02d}_00\" if lat_deg >= 0 else f\"S{abs(lat_deg):02d}_00\"\n",
    "    def fmt_ew(lon_deg: int) -> str:\n",
    "        return f\"E{lon_deg:03d}_00\" if lon_deg >= 0 else f\"W{abs(lon_deg):03d}_00\"\n",
    "    return f\"Copernicus_DSM_COG_10_{fmt_ns(math.floor(lat))}_{fmt_ew(math.floor(lon))}_DEM\"\n",
    "\n",
    "@F.udf(\"boolean\")\n",
    "def tile_exists_udf(tile):\n",
    "    return tile in tile_list_b.value\n",
    "\n",
    "df_run = (df_pts\n",
    "  .withColumn(\"tile_folder\", tile_folder_udf(\"lat\",\"lon\"))\n",
    "  .withColumn(\"tile_exists\", tile_exists_udf(\"tile_folder\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3493d630-ec7f-41e7-894c-ac26806b634c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Explicit output schema for deterministic terrain enrichment results (v3 layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbb7050e-e38e-4dee-b993-94773328f888",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "out_schema = T.StructType([\n",
    "  T.StructField(\"property_id\", T.StringType(), False),\n",
    "  T.StructField(\"lat\", T.DoubleType(), False),\n",
    "  T.StructField(\"lon\", T.DoubleType(), False),\n",
    "  T.StructField(\"radius_m\", T.IntegerType(), False),\n",
    "  T.StructField(\"dem_source\", T.StringType(), False),\n",
    "  T.StructField(\"dem_resolution_m\", T.DoubleType(), False),\n",
    "  T.StructField(\"pipeline_version\", T.StringType(), False),\n",
    "  T.StructField(\"computed_at_utc\", T.StringType(), False),\n",
    "\n",
    "  T.StructField(\"dem_valid_cell_ratio_200m\", T.DoubleType(), True),\n",
    "  T.StructField(\"dem_void_ratio_200m\", T.DoubleType(), True),\n",
    "  T.StructField(\"dem_coverage_label_200m\", T.StringType(), True),\n",
    "\n",
    "  T.StructField(\"elev_min_200m\", T.DoubleType(), True),\n",
    "  T.StructField(\"elev_max_200m\", T.DoubleType(), True),\n",
    "  T.StructField(\"elev_range_200m\", T.DoubleType(), True),\n",
    "\n",
    "  T.StructField(\"slope_p50_pct_200m\", T.DoubleType(), True),\n",
    "  T.StructField(\"slope_p90_pct_200m\", T.DoubleType(), True),\n",
    "  T.StructField(\"slope_max_pct_200m\", T.DoubleType(), True),\n",
    "  T.StructField(\"share_area_slope_gt_8pct_200m\", T.DoubleType(), True),\n",
    "\n",
    "  T.StructField(\"terrain_context_label_200m\", T.StringType(), True),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13259da7-9153-48a8-9554-7d39244eb7cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Partition-level Spark computation: batch listings by DEM tile, extract 200m terrain metrics, and emit rows matching the v3 schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8795745-231e-4ee3-8883-eb1e17d7fb9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PIPELINE_VERSION = \"v3.3-full-spark\"\n",
    "RADIUS_M = 200\n",
    "DEM_SOURCE = \"copernicus_dem_glo30_public\"\n",
    "DEM_RESOLUTION_M = 30.0\n",
    "\n",
    "def v3_partition_compute(pdf_iter):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import rasterio\n",
    "    from rasterio.mask import mask\n",
    "    from shapely.geometry import Point, mapping\n",
    "    from shapely.ops import transform as shp_transform\n",
    "    from pyproj import Transformer\n",
    "    from datetime import datetime\n",
    "\n",
    "    to3857 = Transformer.from_crs(\"EPSG:4326\", \"EPSG:3857\", always_xy=True)\n",
    "\n",
    "    def open_dem(folder: str):\n",
    "        base = \"https://copernicus-dem-30m.s3.amazonaws.com\"\n",
    "        candidates = [\n",
    "            f\"/vsicurl/{base}/{folder}/{folder}.tif\",\n",
    "            f\"/vsicurl/{base}/{folder}/{folder}.tiff\",\n",
    "            f\"/vsicurl/{base}/{folder}/DEM.tif\",\n",
    "            f\"/vsicurl/{base}/{folder}/dem.tif\",\n",
    "        ]\n",
    "        last = None\n",
    "        for url in candidates:\n",
    "            try:\n",
    "                return rasterio.open(url), url\n",
    "            except Exception as e:\n",
    "                last = e\n",
    "        raise last\n",
    "\n",
    "    def buffer_geom_in_src_crs(lon, lat, src_crs, radius_m=200):\n",
    "        x, y = to3857.transform(lon, lat)\n",
    "        poly_3857 = Point(x, y).buffer(radius_m)\n",
    "        tf = Transformer.from_crs(\"EPSG:3857\", src_crs, always_xy=True)\n",
    "        poly_src = shp_transform(lambda xx, yy, zz=None: tf.transform(xx, yy), poly_3857)\n",
    "        return mapping(poly_src)\n",
    "\n",
    "    def valid_mask(elev, nodata):\n",
    "        finite = np.isfinite(elev)\n",
    "        plausible = (elev > 0) & (elev < 9000)\n",
    "        if nodata is None:\n",
    "            return finite & plausible\n",
    "        return finite & plausible & (elev != nodata)\n",
    "\n",
    "    def slope_pct(elev_nan, transform, src_crs, lat_center):\n",
    "        if src_crs is not None and getattr(src_crs, \"is_projected\", False):\n",
    "            dx = transform.a\n",
    "            dy = -transform.e\n",
    "        else:\n",
    "            dx_deg = transform.a\n",
    "            dy_deg = -transform.e\n",
    "            m_per_deg_lat = 111320.0\n",
    "            m_per_deg_lon = 111320.0 * np.cos(np.deg2rad(lat_center))\n",
    "            dx = dx_deg * m_per_deg_lon\n",
    "            dy = dy_deg * m_per_deg_lat\n",
    "        gy, gx = np.gradient(elev_nan.astype(\"float64\"), dy, dx)\n",
    "        return np.sqrt(gx*gx + gy*gy) * 100.0\n",
    "\n",
    "    def coverage_label(r):\n",
    "        if r >= 0.90: return \"good\"\n",
    "        if r >= 0.70: return \"partial\"\n",
    "        return \"poor\"\n",
    "\n",
    "    def terrain_label(cov, slope_p50, share_gt8):\n",
    "        if cov == \"poor\" or slope_p50 is None or share_gt8 is None:\n",
    "            return \"unknown_coverage\"\n",
    "        if slope_p50 <= 5.0 and share_gt8 <= 0.20:\n",
    "            return \"flat_supportive\"\n",
    "        if slope_p50 <= 8.0 and share_gt8 <= 0.35:\n",
    "            return \"moderate\"\n",
    "        return \"steep_challenging\"\n",
    "\n",
    "    for pdf in pdf_iter:\n",
    "        out_rows = []\n",
    "\n",
    "        # group in this partition by tile to avoid re-opening raster per row\n",
    "        for tile, g in pdf.groupby(\"tile_folder\"):\n",
    "            tile_exists = bool(g[\"tile_exists\"].iloc[0])\n",
    "            now = datetime.utcnow().isoformat()\n",
    "\n",
    "            if not tile_exists:\n",
    "                for r in g.itertuples(index=False):\n",
    "                    out_rows.append({\n",
    "                        \"property_id\": str(r.property_id),\n",
    "                        \"lat\": float(r.lat), \"lon\": float(r.lon),\n",
    "                        \"radius_m\": RADIUS_M,\n",
    "                        \"dem_source\": DEM_SOURCE,\n",
    "                        \"dem_resolution_m\": float(DEM_RESOLUTION_M),\n",
    "                        \"pipeline_version\": PIPELINE_VERSION,\n",
    "                        \"computed_at_utc\": now,\n",
    "                        \"dem_valid_cell_ratio_200m\": 0.0,\n",
    "                        \"dem_void_ratio_200m\": 1.0,\n",
    "                        \"dem_coverage_label_200m\": \"poor\",\n",
    "                        \"elev_min_200m\": None, \"elev_max_200m\": None, \"elev_range_200m\": None,\n",
    "                        \"slope_p50_pct_200m\": None, \"slope_p90_pct_200m\": None, \"slope_max_pct_200m\": None,\n",
    "                        \"share_area_slope_gt_8pct_200m\": None,\n",
    "                        \"terrain_context_label_200m\": \"unknown_coverage\",\n",
    "                    })\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                src, _ = open_dem(tile)\n",
    "            except Exception:\n",
    "                for r in g.itertuples(index=False):\n",
    "                    out_rows.append({\n",
    "                        \"property_id\": str(r.property_id),\n",
    "                        \"lat\": float(r.lat), \"lon\": float(r.lon),\n",
    "                        \"radius_m\": RADIUS_M,\n",
    "                        \"dem_source\": DEM_SOURCE,\n",
    "                        \"dem_resolution_m\": float(DEM_RESOLUTION_M),\n",
    "                        \"pipeline_version\": PIPELINE_VERSION,\n",
    "                        \"computed_at_utc\": now,\n",
    "                        \"dem_valid_cell_ratio_200m\": 0.0,\n",
    "                        \"dem_void_ratio_200m\": 1.0,\n",
    "                        \"dem_coverage_label_200m\": \"poor\",\n",
    "                        \"elev_min_200m\": None, \"elev_max_200m\": None, \"elev_range_200m\": None,\n",
    "                        \"slope_p50_pct_200m\": None, \"slope_p90_pct_200m\": None, \"slope_max_pct_200m\": None,\n",
    "                        \"share_area_slope_gt_8pct_200m\": None,\n",
    "                        \"terrain_context_label_200m\": \"unknown_coverage\",\n",
    "                    })\n",
    "                continue\n",
    "\n",
    "            with src:\n",
    "                nodata = src.nodata\n",
    "                src_crs = src.crs\n",
    "\n",
    "                for r in g.itertuples(index=False):\n",
    "                    now2 = datetime.utcnow().isoformat()\n",
    "                    try:\n",
    "                        geom = buffer_geom_in_src_crs(float(r.lon), float(r.lat), src_crs, RADIUS_M)\n",
    "                        out, out_transform = mask(src, [geom], crop=True, all_touched=True)\n",
    "                        elev = out[0].astype(\"float64\")\n",
    "\n",
    "                        valid = valid_mask(elev, nodata)\n",
    "                        total = elev.size\n",
    "                        ratio = float(valid.sum() / total) if total > 0 else 0.0\n",
    "                        cov = coverage_label(ratio)\n",
    "\n",
    "                        if cov == \"poor\":\n",
    "                            out_rows.append({\n",
    "                                \"property_id\": str(r.property_id),\n",
    "                                \"lat\": float(r.lat), \"lon\": float(r.lon),\n",
    "                                \"radius_m\": RADIUS_M,\n",
    "                                \"dem_source\": DEM_SOURCE,\n",
    "                                \"dem_resolution_m\": float(DEM_RESOLUTION_M),\n",
    "                                \"pipeline_version\": PIPELINE_VERSION,\n",
    "                                \"computed_at_utc\": now2,\n",
    "                                \"dem_valid_cell_ratio_200m\": ratio,\n",
    "                                \"dem_void_ratio_200m\": 1.0 - ratio,\n",
    "                                \"dem_coverage_label_200m\": cov,\n",
    "                                \"elev_min_200m\": None, \"elev_max_200m\": None, \"elev_range_200m\": None,\n",
    "                                \"slope_p50_pct_200m\": None, \"slope_p90_pct_200m\": None, \"slope_max_pct_200m\": None,\n",
    "                                \"share_area_slope_gt_8pct_200m\": None,\n",
    "                                \"terrain_context_label_200m\": \"unknown_coverage\",\n",
    "                            })\n",
    "                            continue\n",
    "\n",
    "                        elev_v = elev[valid]\n",
    "                        elev_min = float(elev_v.min())\n",
    "                        elev_max = float(elev_v.max())\n",
    "                        elev_range = float(elev_max - elev_min)\n",
    "\n",
    "                        elev_nan = elev.copy()\n",
    "                        elev_nan[~valid] = np.nan\n",
    "\n",
    "                        s = slope_pct(elev_nan, out_transform, src_crs, float(r.lat))\n",
    "                        slope_ok = valid & np.isfinite(s)\n",
    "\n",
    "                        if slope_ok.sum() == 0:\n",
    "                            out_rows.append({\n",
    "                                \"property_id\": str(r.property_id),\n",
    "                                \"lat\": float(r.lat), \"lon\": float(r.lon),\n",
    "                                \"radius_m\": RADIUS_M,\n",
    "                                \"dem_source\": DEM_SOURCE,\n",
    "                                \"dem_resolution_m\": float(DEM_RESOLUTION_M),\n",
    "                                \"pipeline_version\": PIPELINE_VERSION,\n",
    "                                \"computed_at_utc\": now2,\n",
    "                                \"dem_valid_cell_ratio_200m\": ratio,\n",
    "                                \"dem_void_ratio_200m\": 1.0 - ratio,\n",
    "                                \"dem_coverage_label_200m\": cov,\n",
    "                                \"elev_min_200m\": elev_min, \"elev_max_200m\": elev_max, \"elev_range_200m\": elev_range,\n",
    "                                \"slope_p50_pct_200m\": None, \"slope_p90_pct_200m\": None, \"slope_max_pct_200m\": None,\n",
    "                                \"share_area_slope_gt_8pct_200m\": None,\n",
    "                                \"terrain_context_label_200m\": \"unknown_coverage\",\n",
    "                            })\n",
    "                            continue\n",
    "\n",
    "                        s_v = s[slope_ok]\n",
    "                        slope_p50 = float(np.percentile(s_v, 50))\n",
    "                        slope_p90 = float(np.percentile(s_v, 90))\n",
    "                        slope_max = float(s_v.max())\n",
    "                        share_gt8 = float(np.mean(s_v > 8.0))\n",
    "\n",
    "                        label = terrain_label(cov, slope_p50, share_gt8)\n",
    "\n",
    "                        out_rows.append({\n",
    "                            \"property_id\": str(r.property_id),\n",
    "                            \"lat\": float(r.lat), \"lon\": float(r.lon),\n",
    "                            \"radius_m\": RADIUS_M,\n",
    "                            \"dem_source\": DEM_SOURCE,\n",
    "                            \"dem_resolution_m\": float(DEM_RESOLUTION_M),\n",
    "                            \"pipeline_version\": PIPELINE_VERSION,\n",
    "                            \"computed_at_utc\": now2,\n",
    "                            \"dem_valid_cell_ratio_200m\": ratio,\n",
    "                            \"dem_void_ratio_200m\": 1.0 - ratio,\n",
    "                            \"dem_coverage_label_200m\": cov,\n",
    "                            \"elev_min_200m\": elev_min, \"elev_max_200m\": elev_max, \"elev_range_200m\": elev_range,\n",
    "                            \"slope_p50_pct_200m\": slope_p50,\n",
    "                            \"slope_p90_pct_200m\": slope_p90,\n",
    "                            \"slope_max_pct_200m\": slope_max,\n",
    "                            \"share_area_slope_gt_8pct_200m\": share_gt8,\n",
    "                            \"terrain_context_label_200m\": label,\n",
    "                        })\n",
    "\n",
    "                    except Exception:\n",
    "                        out_rows.append({\n",
    "                            \"property_id\": str(r.property_id),\n",
    "                            \"lat\": float(r.lat), \"lon\": float(r.lon),\n",
    "                            \"radius_m\": RADIUS_M,\n",
    "                            \"dem_source\": DEM_SOURCE,\n",
    "                            \"dem_resolution_m\": float(DEM_RESOLUTION_M),\n",
    "                            \"pipeline_version\": PIPELINE_VERSION,\n",
    "                            \"computed_at_utc\": now2,\n",
    "                            \"dem_valid_cell_ratio_200m\": 0.0,\n",
    "                            \"dem_void_ratio_200m\": 1.0,\n",
    "                            \"dem_coverage_label_200m\": \"poor\",\n",
    "                            \"elev_min_200m\": None, \"elev_max_200m\": None, \"elev_range_200m\": None,\n",
    "                            \"slope_p50_pct_200m\": None, \"slope_p90_pct_200m\": None, \"slope_max_pct_200m\": None,\n",
    "                            \"share_area_slope_gt_8pct_200m\": None,\n",
    "                            \"terrain_context_label_200m\": \"unknown_coverage\",\n",
    "                        })\n",
    "\n",
    "        yield pd.DataFrame(out_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a6edffd-10a9-42d1-9347-261d8f6f7125",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Execute distributed terrain enrichment and write the finalized v3 Delta table (overwrite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f495296b-5686-4f10-b34e-a2c9cf9c4435",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_exec = df_run.repartition(256, \"tile_folder\")\n",
    "\n",
    "df_v3 = df_exec.mapInPandas(v3_partition_compute, schema=out_schema)\n",
    "\n",
    "(df_v3.write.format(\"delta\")\n",
    "     .mode(\"overwrite\")\n",
    "     .option(\"overwriteSchema\", \"true\")\n",
    "     .saveAsTable(\"default.access4all_airbnb_v3_terrain_9cities\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "448beec3-819f-4f6c-937f-4f54a5b16b8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Deduplicate v3 results to the latest computation per property and persist the canonical terrain table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3f8de75-90b8-4191-b1aa-576b6c7fdbdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "v3 = spark.table(\"default.access4all_airbnb_v3_terrain_9cities\")\n",
    "\n",
    "w = Window.partitionBy(\"property_id\").orderBy(F.col(\"computed_at_utc\").desc())\n",
    "\n",
    "v3_dedup = (\n",
    "    v3.withColumn(\"rn\", F.row_number().over(w))\n",
    "      .filter(F.col(\"rn\") == 1)\n",
    "      .drop(\"rn\")\n",
    ")\n",
    "\n",
    "(v3_dedup.write.format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(\"default.access4all_airbnb_v3_terrain_9cities\"))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_terrain_slope_layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}